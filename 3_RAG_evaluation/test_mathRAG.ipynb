{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suigpt_rag/miniconda3/envs/new_CG/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. import testing Question dataset [Q]\n",
    "with open(\"../math_qa_all.json\", \"r\") as qf:\n",
    "    data = json.load(qf)\n",
    "    questions: list = [q['Q'] for q in data]\n",
    "    questions_page: list = [q['page'] for q in data]\n",
    "    questions_answer: list = [q['A'] for q in data]\n",
    "\n",
    "# import book by pages [P]\n",
    "with open(\"../0906_request.jsonl_output.json\", \"r\") as pf:\n",
    "    data = json.load(pf)\n",
    "    pages:list = [data[i]['response']['body']['choices'][0]['message']['content'] for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. import possible models [M]\n",
    "models_list: list = ['thenlper/gte-large']\n",
    "\n",
    "# 2.1 model retrieved results [M * Q] = -1\n",
    "# retrieved_results = [None for i in range(len(questions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. For every model in model list\n",
    "# for model_name in models_list: \n",
    "# 3s for loading existing model\n",
    "model_name = models_list[0]\n",
    "\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12.3s\n",
    "# page_embeddings = []\n",
    "# 3.1. create embedding for each page, store it in numpy [P * E], E = embedding size\n",
    "page_embeddings: np.ndarray = model.encode(pages) \n",
    "# for page in pages:\n",
    "#     embeddings = model.encode(page)\n",
    "#     page_embeddings.append(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.7s\n",
    "# 3.2. for each question in QA dataset, query the question [Q * E]\n",
    "questions_embeddings: np.ndarray  = model.encode(questions)\n",
    "# questions_embeddings = []\n",
    "# for question in questions:\n",
    "#     embedding = model.encode(question)\n",
    "#     questions_embeddings.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.8s\n",
    "# 3.3. for each question, search the retrieved page rank (index of the numpy 2D array) \n",
    "# by calculating the difference between the retrieved page and the true page.\n",
    "# [Q * K]\n",
    "\n",
    "# retrieved_page_ranks = []\n",
    "\n",
    "all_pages = []\n",
    "for i in range(len(pages)):\n",
    "    temp_dict: dict = {}\n",
    "    temp_dict['page_number'] = questions_page[i]\n",
    "    temp_dict['question'] = questions[i]\n",
    "    temp_dict['answer'] = questions_answer[i]\n",
    "\n",
    "for i in range(len(questions)):\n",
    "    temp_dict: dict = {}\n",
    "    temp_dict['question_page'] = questions_page[i]\n",
    "    temp_dict['question'] = questions[i]\n",
    "    temp_dict['answer'] = questions_answer[i]\n",
    "\n",
    "# retrieved_page_ranks = []\n",
    "# for question_embedding in questions_embeddings:\n",
    "#     question_retrived_page_rank = [float(cos_sim(question_embedding, page_embed)) for page_embed in page_embeddings]\n",
    "#     sorted_pages = list(np.argsort(question_retrived_page_rank))\n",
    "#     sorted_pages = [i + 1 for i in sorted_pages]\n",
    "#     retrieved_page_ranks.append(sorted_pages)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4, for each question, calculate the @1, @3, @10 accuracies. [Q], [Q], [Q]\n",
    "top1 = 0\n",
    "top3 = 0\n",
    "top10 = 0\n",
    "top20 = 0\n",
    "for question_index in range(len(retrieved_page_ranks)):\n",
    "    true_question_page_index = questions_page[question_index]\n",
    "    retrived_page_rank = retrieved_page_ranks[question_index]\n",
    "\n",
    "    # print(f\"true_question_page_index: {true_question_page_index}\")\n",
    "    # print(f\"retrived_page_rank: {retrived_page_rank}\")\n",
    "\n",
    "    # tops\n",
    "    if true_question_page_index in retrived_page_rank[:1]: top1 += 1\n",
    "    if true_question_page_index in retrived_page_rank[:3]: top3 += 1\n",
    "    if true_question_page_index in retrived_page_rank[:10]: top10 += 1\n",
    "    if true_question_page_index in retrived_page_rank[:20]: top20 += 1\n",
    "\n",
    "# print(top1)\n",
    "# print(top3)\n",
    "# print(top10)\n",
    "# print(top20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of test accuracy, test relative distance\n",
    "top1d = 0\n",
    "top3d = 0\n",
    "top10d = 0\n",
    "top20d = 0\n",
    "\n",
    "for question_index in range(len(retrieved_page_ranks)):\n",
    "    true_question_page_index = questions_page[question_index]\n",
    "    retrived_page_rank = retrieved_page_ranks[question_index]\n",
    "    top1d += min(abs(i - true_question_page_index) for i in retrived_page_rank[:1])\n",
    "    top3d += min(abs(i - true_question_page_index) for i in retrived_page_rank[:3])\n",
    "    top10d += min(abs(i - true_question_page_index) for i in retrived_page_rank[:10])\n",
    "    top20d += min(abs(i - true_question_page_index) for i in retrived_page_rank[:20])\n",
    "    \n",
    "\n",
    "# top1d /= len(retrieved_page_ranks)\n",
    "# top3d /= len(retrieved_page_ranks)\n",
    "# top10d /= len(retrieved_page_ranks)\n",
    "# top20d /= len(retrieved_page_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296.83666666666664\n",
      "149.93\n",
      "63.25333333333333\n",
      "37.05\n"
     ]
    }
   ],
   "source": [
    "# print(top1d)\n",
    "# print(top3d)\n",
    "# print(top10d)\n",
    "# print(top20d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in models_list: \n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    # 3.1. create embedding for each page, store it in numpy [P * E], E = embedding size\n",
    "    page_embeddings = []\n",
    "    for page in pages:\n",
    "        embeddings = model.encode(page)\n",
    "        page_embeddings.append(embeddings)\n",
    "\n",
    "    # 3.2. for each question in QA dataset, query the question [Q * E]\n",
    "    questions_embeddings = []\n",
    "    for question in questions:\n",
    "        embedding = model.encode(question)\n",
    "        questions_embeddings.append(embedding)\n",
    "\n",
    "\n",
    "    # 3.3. for each question, search the retrieved page rank (index of the numpy 2D array) \n",
    "    # by calculating the difference between the retrieved page and the true page.\n",
    "    # [Q * K]\n",
    "    retrieved_page_ranks = []\n",
    "    for question_embedding in questions_embeddings:\n",
    "        question_retrived_page_rank = [float(cos_sim(question_embedding, pe)) for pe in page_embeddings]\n",
    "        sorted_pages = list(np.argsort(question_retrived_page_rank))\n",
    "        sorted_pages = [i + 1 for i in sorted_pages]\n",
    "        retrieved_page_ranks.append(sorted_pages)\n",
    "        break\n",
    "\n",
    "    # 3.4, for each question, calculate the @1, @3, @10 accuracies. [Q], [Q], [Q]\n",
    "    top1 = 0\n",
    "    top3 = 0\n",
    "    top10 = 0\n",
    "    top20 = 0\n",
    "    for question_index in range(len(retrieved_page_ranks)):\n",
    "        true_question_page_index = questions_page[question_index]\n",
    "        retrived_page_rank = retrieved_page_ranks[question_index]\n",
    "\n",
    "        # print(f\"true_question_page_index: {true_question_page_index}\")\n",
    "        # print(f\"retrived_page_rank: {retrived_page_rank}\")\n",
    "\n",
    "        # tops\n",
    "        if true_question_page_index in retrived_page_rank[:1]: top1 += 1\n",
    "        if true_question_page_index in retrived_page_rank[:3]: top3 += 1\n",
    "        if true_question_page_index in retrived_page_rank[:10]: top10 += 1\n",
    "        if true_question_page_index in retrived_page_rank[:20]: top20 += 1\n",
    "    \n",
    "    # 3.4.1 instead of test accuracy, test relative distance\n",
    "    top1d = 0\n",
    "    top3d = 0\n",
    "    top10d = 0\n",
    "    top20d = 0\n",
    "\n",
    "    for question_index in range(len(retrieved_page_ranks)):\n",
    "        true_question_page_index = questions_page[question_index]\n",
    "        retrived_page_rank = retrieved_page_ranks[question_index]\n",
    "        top1d += min(abs(i - true_question_page_index) for i in retrived_page_rank[:1])\n",
    "        top3d += min(abs(i - true_question_page_index) for i in retrived_page_rank[:3])\n",
    "        top10d += min(abs(i - true_question_page_index) for i in retrived_page_rank[:10])\n",
    "        top20d += min(abs(i - true_question_page_index) for i in retrived_page_rank[:20])\n",
    "        \n",
    "\n",
    "    top1d /= len(retrieved_page_ranks)\n",
    "    top3d /= len(retrieved_page_ranks)\n",
    "    top10d /= len(retrieved_page_ranks)\n",
    "    top20d /= len(retrieved_page_ranks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
