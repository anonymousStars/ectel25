{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    return encoded_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv, os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "dotenv.load_dotenv()\n",
    "openai.api_key  = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to call GPT-4 with one image and a prompt\n",
    "def get_message_json(image_base64):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant. Given an image of a PDF page,\" +\n",
    "                          \"please extract the text and convert it to Markdown format,\" +\n",
    "                          \"You may use LaTeX for mathematical equations,\" +\n",
    "                          \"You should ignore headers, footers, page numbers,\" +\n",
    "                          \"and other non text contents such as images, figures, and meaningless symbols. \" +\n",
    "                          \"Keep the table and fomulas as markdown format.\" +\n",
    "                          \"Output the Markdown content only within <markdown> tags.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Here is the image of the page I want to extract:\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{image_base64}\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "    return messages\n",
    "\n",
    "\n",
    "def get_completion_from_image(image_base64, model=\"gpt-4o-2024-08-06\", temperature=0):\n",
    "    messages = get_message_json(image_base64)\n",
    "    response = client.chat.completions.create(\n",
    "        model=model, messages=messages, temperature=temperature\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message.content\n",
    "    token_dict = {\n",
    "        \"prompt_tokens\": response.usage.prompt_tokens,\n",
    "        \"completion_tokens\": response.usage.completion_tokens,\n",
    "        \"total_tokens\": response.usage.total_tokens,\n",
    "    }\n",
    "    return content, token_dict\n",
    "\n",
    "\n",
    "# {\"custom_id\": \"request-1\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-4o-2024-08-06\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},{\"role\": \"user\", \"content\": \"Hello world!\"}],\"max_tokens\": 9999}}\n",
    "# Above is a jsonl row of a request to openai api\n",
    "import hashlib\n",
    "import random\n",
    "def get_request_jsonl(image_base64, model=\"gpt-4o-2024-08-06\", temperature=0):\n",
    "    messages = get_message_json(image_base64)\n",
    "    # get hash of image_base64\n",
    "    hash_object = hashlib.sha256()\n",
    "    hash_object.update(image_base64.encode('utf-8'))\n",
    "    image_hash = hash_object.hexdigest()\n",
    "    # get random number between 0 and 100000000\n",
    "    random_number = random.randint(0, 100000000)\n",
    "    request_jsonl = {\n",
    "        \"custom_id\": f\"{image_hash}_{random_number}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": model,\n",
    "            \"messages\": messages,\n",
    "            \"max_tokens\": 9999,\n",
    "            \"temperature\": temperature,\n",
    "        }\n",
    "    }\n",
    "    return request_jsonl\n",
    "\n",
    "# Example of usage:\n",
    "# image_path = \"./textbook_screenshot/1.png\"  # Your image path\n",
    "# encoded_image = encode_image_to_base64(image_path)\n",
    "# response, token_usage = get_completion_from_image(encoded_image)\n",
    "\n",
    "# print(\"Markdown output:\")\n",
    "# print(response)\n",
    "# print(\"Token usage:\")\n",
    "# print(token_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Function to get the largest image index from the directory\n",
    "def get_max_image_count(directory):\n",
    "    # List all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "    \n",
    "    # Use regex to match files with the format {i}.png\n",
    "    image_files = [f for f in files if re.match(r\"(\\d+)\\.png\", f)]\n",
    "    \n",
    "    if not image_files:\n",
    "        return 0  # If no image files are found, return 0\n",
    "    \n",
    "    # Extract the numbers from the filenames and convert them to integers\n",
    "    image_numbers = [int(re.match(r\"(\\d+)\\.png\", f).group(1)) for f in image_files]\n",
    "    \n",
    "    # Return the maximum number found\n",
    "    return max(image_numbers)\n",
    "\n",
    "# Function to save the markdown content between <markdown> tags\n",
    "def save_markdown_from_response(response, i):\n",
    "    # Use regex to extract content within <markdown> tags\n",
    "    markdown_content = re.search(r\"<markdown>(.*?)</markdown>\", response, re.DOTALL)\n",
    "    # Edge case: if <markdown> tags are not found, but no </markdown> tags are found, then the markdown_content will be all content after <markdown> tags\n",
    "    if not markdown_content:\n",
    "        markdown_content = re.search(r\"<markdown>(.*)\", response, re.DOTALL)\n",
    "    \n",
    "    if markdown_content:\n",
    "        # Get the matched markdown content\n",
    "        markdown_content = markdown_content.group(1).strip()\n",
    "        \n",
    "        # Directory where markdown files are saved\n",
    "        output_dir = \"./textbook_markdown/\"\n",
    "        os.makedirs(output_dir, exist_ok=True)  # Create directory if not exists\n",
    "        \n",
    "        # File path\n",
    "        file_path = os.path.join(output_dir, f\"{i}.md\")\n",
    "        \n",
    "        # Check if the file already exists\n",
    "        if os.path.exists(file_path):\n",
    "            print(f\"File {file_path} already exists. Skipping.\", end = \"\\r\")\n",
    "        else:\n",
    "            # Save the content to a markdown file\n",
    "            if markdown_content:\n",
    "                with open(file_path, \"w\") as md_file:\n",
    "                    md_file.write(markdown_content)\n",
    "                print(f\"Saved markdown to {file_path}\", end = \"\\r\")\n",
    "            else:\n",
    "                # Save empty file if no markdown content\n",
    "                with open(file_path, \"w\") as md_file:\n",
    "                    md_file.write(\"\")  # Write empty content\n",
    "                print(f\"Saved empty markdown to {file_path}\", end = \"\\r\")\n",
    "    else:\n",
    "        print(f\"No markdown content found in response for page {i}. Saving empty file.\", end = \"\\r\")\n",
    "        # Save an empty file when there's no markdown content\n",
    "        file_path = os.path.join(\"./textbook_markdown/\", f\"{i}.md\")\n",
    "        with open(file_path, \"w\") as md_file:\n",
    "            md_file.write(\"\")  # Write empty content\n",
    "\n",
    "import json\n",
    "def save_token_usage(token_usage, i):\n",
    "    # save the token usage to a json file at ./token_usage/{i}.json\n",
    "    with open(f\"./token_usage/{i}.json\", \"w\") as f:\n",
    "        json.dump(token_usage, f)\n",
    "\n",
    "# Example of usage with loop:\n",
    "def process_pdf_images():\n",
    "    # Determine the image count based on available PNG files\n",
    "    screenshot_dir = \"./textbook_screenshot/\"\n",
    "    image_count = get_max_image_count(screenshot_dir)\n",
    "    \n",
    "    for i in range(1, image_count + 1):  # Loop through all images\n",
    "        file_path = os.path.join(\"./textbook_markdown/\", f\"{i}.md\")\n",
    "        \n",
    "        # Check if the markdown file already exists\n",
    "        if os.path.exists(file_path):\n",
    "            print(f\"Markdown file {file_path} already exists. Skipping image {i}.\", end = \"\\r\")\n",
    "            continue  # Skip processing this image\n",
    "        \n",
    "        image_path = os.path.join(screenshot_dir, f\"{i}.png\")\n",
    "        \n",
    "        # If the image file exists, proceed\n",
    "        if os.path.exists(image_path):\n",
    "            encoded_image = encode_image_to_base64(image_path)\n",
    "            request_jsonl = get_request_jsonl(encoded_image)\n",
    "            # append the request_jsonl to a jsonl file\n",
    "            with open(jsonl_file_path, \"a\") as f:\n",
    "                f.write(json.dumps(request_jsonl) + \"\\n\")\n",
    "        else:\n",
    "            print(f\"Image file {image_path} does not exist. Skipping.\", end = \"\\r\")\n",
    "\n",
    "# Example call for processing a PDF with multiple pages\n",
    "jsonl_file_path = \"./0906_request.jsonl\"\n",
    "process_pdf_images()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(jsonl_file_path, \"r\") as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "628"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# 定義拆分檔案的函數\n",
    "def split_jsonl_file(jsonl_file_path, lines_per_file=200):\n",
    "    with open(jsonl_file_path, \"r\", encoding=\"utf-8\") as infile:\n",
    "        lines = infile.readlines()\n",
    "\n",
    "    # 依照行數分割成多個檔案\n",
    "    for i in range(0, len(lines), lines_per_file):\n",
    "        batch_lines = lines[i:i + lines_per_file]\n",
    "        batch_file_path = f\"{jsonl_file_path}_batch_{i//lines_per_file}.jsonl\"\n",
    "        with open(batch_file_path, \"w\", encoding=\"utf-8\") as batch_file:\n",
    "            batch_file.writelines(batch_lines)\n",
    "        yield batch_file_path\n",
    "\n",
    "# 上傳分批的檔案\n",
    "def upload_batches(jsonl_file_path):\n",
    "    batch_file_paths = list(split_jsonl_file(jsonl_file_path))\n",
    "    batch_input_files = []\n",
    "    for batch_file_path in batch_file_paths:\n",
    "        with open(batch_file_path, \"rb\") as batch_file:\n",
    "            batch_input_file = client.files.create(\n",
    "                file=batch_file,\n",
    "                purpose=\"batch\",\n",
    "            )\n",
    "        batch_input_files.append(batch_input_file)\n",
    "        # print(f\"Uploaded {batch_file_path}, file id: {batch_input_file['id']}\")\n",
    "      \n",
    "    return batch_input_files\n",
    "\n",
    "# 呼叫 upload_batches 函數上傳檔案\n",
    "batch_input_files = upload_batches(jsonl_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FileObject(id='file-WI0JlFm5TMR8ZNm1S6eysd62', bytes=82205180, created_at=1725624597, filename='0906_request.jsonl_batch_0.jsonl', object='file', purpose='batch', status='processed', status_details=None),\n",
       " FileObject(id='file-6B3ZODKvddSa89G2ru30io1o', bytes=87229431, created_at=1725624632, filename='0906_request.jsonl_batch_1.jsonl', object='file', purpose='batch', status='processed', status_details=None),\n",
       " FileObject(id='file-t2EzdNyZuUmvoJLwfSTRjuRJ', bytes=86938125, created_at=1725624667, filename='0906_request.jsonl_batch_2.jsonl', object='file', purpose='batch', status='processed', status_details=None),\n",
       " FileObject(id='file-CdHsRgzHfTiEhZe034BFnOyy', bytes=12316211, created_at=1725624675, filename='0906_request.jsonl_batch_3.jsonl', object='file', purpose='batch', status='processed', status_details=None)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(batch_input_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = []\n",
    "for batch_input_file in batch_input_files:\n",
    "    batch_input_file_id = batch_input_file.id\n",
    "\n",
    "    result = client.batches.create(\n",
    "        input_file_id=batch_input_file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\n",
    "          \"description\": \"nightly eval job\" + batch_input_file_id\n",
    "        }\n",
    "    )\n",
    "    jobs.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save batch job id to a json file\n",
    "batch_job_ids = [job.id for job in jobs]\n",
    "with open(f\"./{jsonl_file_path}batch_job_ids.json\", \"w\") as f:\n",
    "    json.dump(batch_job_ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Batch(id='batch_k0kFYGIADP2J5F8ued9EfOzt', completion_window='24h', created_at=1725624677, endpoint='/v1/chat/completions', input_file_id='file-CdHsRgzHfTiEhZe034BFnOyy', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725711077, failed_at=None, finalizing_at=None, in_progress_at=1725624678, metadata={'description': 'nightly eval jobfile-CdHsRgzHfTiEhZe034BFnOyy'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=28)),\n",
       " Batch(id='batch_kdwLHYNDWaVf4Rw4KDhzPhSC', completion_window='24h', created_at=1725624677, endpoint='/v1/chat/completions', input_file_id='file-t2EzdNyZuUmvoJLwfSTRjuRJ', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725711077, failed_at=None, finalizing_at=None, in_progress_at=1725624680, metadata={'description': 'nightly eval jobfile-t2EzdNyZuUmvoJLwfSTRjuRJ'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=200)),\n",
       " Batch(id='batch_lqS68bfqTjGCI0erFaB90gM3', completion_window='24h', created_at=1725624677, endpoint='/v1/chat/completions', input_file_id='file-6B3ZODKvddSa89G2ru30io1o', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725711077, failed_at=None, finalizing_at=None, in_progress_at=1725624679, metadata={'description': 'nightly eval jobfile-6B3ZODKvddSa89G2ru30io1o'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=200)),\n",
       " Batch(id='batch_KoBg3DZn8Ibsx9KQ5UgDbm7J', completion_window='24h', created_at=1725624676, endpoint='/v1/chat/completions', input_file_id='file-WI0JlFm5TMR8ZNm1S6eysd62', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725711076, failed_at=None, finalizing_at=None, in_progress_at=1725624678, metadata={'description': 'nightly eval jobfile-WI0JlFm5TMR8ZNm1S6eysd62'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=200))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = client.batches.list()\n",
    "result.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
